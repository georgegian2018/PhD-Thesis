%*******************************************************************************
%*********************************** First Chapter *****************************
%*******************************************************************************

\chapter{The rise of single cell RNA-seq experiments} \label{ch:intro}

\graphicspath{{Chapter1/Figs/}}

The measurement of the transcriptome of single-cells has only become possible over the last few years, but is becoming an extremely popular assay. While many types of analysis and questions can be answered using single cell RNA-sequencing, of prime interest is the ability to investigate what cell types occur in nature. Unbiased and reproducible cataloging of distinct cell types require large numbers of cells to be sampled. Technological development and improvement of protocols has exponentially scaled the size of single cell RNA-seq studies, much faster than Moore’s Law. In this perspective we will illustrate the steps that facilitated this growth, and will discuss the implications for our ability to define cell types.

\section{Introduction}

Cells are the fundamental units of life and cell differentiation allows the generation of complex multicellular organisms. This variety of cells is made possible because cells exhibit different identities that are determined intrinsically (as a consequence of development) and extrinsically by their environment. The molecular mechanisms that regulate cell state and function are of fundamental interest, as key determinants of the cell phenotype, inform on developmental origin and tissue context.

Regulation of cell state and function occurs significantly at the mRNA level, with transcription factors defining a cell’s transcriptional “programme”. In light of this, the abundances of different RNAs within cells are representative of functionally relevant cellular states. The ability to measure RNA in cells ties together cell biology, in terms of cellular phenotypes, with molecular biology, in terms of regulation of function. Shortly after the advent of RNA sequencing as a biological tool \cite{Mortazavi2008-rq}, researchers started working on adapting the technology to single cells. Imaging-based assays such as in situ hybridization for RNA, or immunostaining for proteins had long revealed that population level averages were not representative of individual cell states \cite{Raj2008-wj}.

Over the last few years, many sensitive and accurate single-cell RNA-sequencing
(scRNA-Seq) protocols have been developed \cite{Svensson2017-pf}.

\begin{figure}
    \centering
    \centerline{\includegraphics[width=\textwidth]{"main-figure"}}
    \caption[Scaling single cell transcriptomics]{\textbf{Scaling single cell transcriptomics.} Since the advent of single cell RNA sequencing, key technologies (top) have advanced the scale of single cell RNA-seq studies. Representative studies over the years are illustrated with their publication dates compared to their sample sizes (bottom). Key technological advances are named and annotated in the figure close to the corresponding study.}
    \label{fig:scaling}
\end{figure}

In this chapter, we show that single cell transcriptome experiments have grown exponentially, up to hundreds of thousands cells per study, in less than a decade (Figure \ref{fig:scaling}). We also highlight what this has meant for the investigation of cell states\footnote{\textit{Cell state} refer to cases where cells are transiently distinct, by expressing genes or carry some other phenotype.}, cell types\footnote{\textit{Cell type} on the other hand refer to cases when cells are terminally differentiated and locked to a phenotype, e.g. by epigenetic marks. The exact dilenation between these two notions can however often be hard to dinstinguish.} and other sources of cell-to-cell variation.

\section{From tens to hundreds of cells}

The increase in multiplexing of samples is driven by two factors: (i) reduction in the volume of reagents per sample and (ii) parallel processing of samples.

In the first single-cell RNA-seq study published eight years ago by \citet{Tang2009-af}, a single 4-cell stage blastomere was manually isolated using a glass capillary. The entire RNA-sequencing procedure was performed on the cell individually. The motivation was to make the most of precious embryonic samples compared to microarray techniques. The original method by Tang et al requires multiple PCR tubes for each cell, and a gel purification step \cite{Sasagawa2013-ps, Tang2010-am}.

Since it was known that intrinsic transcriptional variation might cause measurement issues, a technique called STRT-Seq was developed and presented in a study by \citet{Islam2011-yy}. Up to 85 samples were multiplexed to characterize the transcriptional landscape of MEFs and mESCs. At the time, the value of multiplexing strategies started to be recognized as a means to allow higher throughput of sequencing experiments in general \cite{Kozarewa2011-we}. In this technique, the 96 cells are added to individual wells, and cell specific barcodes are added using the template-switching mechanism of reverse transcriptase during cDNA generation independently for each sample. The material from each well is then pooled before it is amplified by PCR. From the results of \citet{Islam2011-yy}, it was clear that while there was a great degree of intrinsic variation between cells of the same type, embryonic stem cells (mESC) could be distinguished from MEF cells based on the transcriptome, illustrating the notion of a transcriptional cell state. This served as a pilot for future studies where cells would be randomly sampled, and not have \textit{a priori} annotated cell types and \textit{de novo} annotated.

The ability to distinguish cell types by single cell transcriptomics was also demonstrated by \cite{Hashimshony2012-am}, who introduced the CEL-seq technique. As with STRT-seq, cells in individual wells are barcoded during cDNA synthesis and pooled, but rather than using PCR, the material is amplified by in vitro transcription (IVT).

Illumina, Inc. introduced highly multiplexed procedures for Illumina sequencing using dual-index barcoding in the form of the transposase-based ‘tagmentation’ with the Nextera XT kits \cite{Illumina_Inc2012-mf}. This meant that multiplexing cells could be simplified by commercially available kits, allowing up to 192 samples per Illumina sequencing lane. The SMART-seq technique was introduced as a single-cell sequencing technology by Ramskold et al \cite{Ramskold2012-zc}, giving full length coverage of transcripts using the SMART template switching technology. The data generated was more familiar to users of traditional RNA-sequencing, making bioinformatics processing easier. This method made use of the Nextera kit for multiplexing and library generation. The Smart-seq technique made scRNA-seq experiments widely accessible by becoming readily available as the SMARTer kit from Clontech \cite{Clontech_Laboratories_Inc2013-zf}. A drawback compared to STRT- and CEL-seq is that amplification and library generation must be carried out for all the cells individually, increasing the processing time.

While readily available and easy to use (Smart-seq has a smaller number of experimental steps than STRT-Seq or CEL-Seq), the cost per sample using the SMARTer kit was prohibitive when scaling up to the numbers in the STRT-seq and CEL-seq applications. Indeed, none of the published studies using this technique in microwells processed more than 20 cells \cite{Ramskold2012-zc, Marinov2014-bf, Shalek2013-lw}. While it was noted that discrete cell states could be identified \cite{Shalek2013-lw}, it became clear that more statistical power through increased sample numbers would be helpful. Two parallel strategies emerged to tackle this: reducing the reaction volume per cell and the use of cheaper reagents for similar goals. The introduction of the Fluidigm C1 system improved the reagent cost, by letting the reaction occur in nanoliter chambers of an integrated fluidic circuit (IFC) \cite{Fluidigm_Corporation2013-vw}. The system also simplified cell isolation, as users were simply able to load a cell suspension into the system. Cells were automatically captured in 96 chambers of the IFC and processed material could later be transferred to microwell plates \cite{Wu2014-ot, Brennecke2013-vv}. Recently, a higher throughput version of the IFC allowing up to 800 cells to be captured was announced \cite{Fluidigm_Corporation2016-jl}. The use of \(\sim 100 \) samples allowed researchers to estimate variance and decompose it into biological and technical noise \cite{Brennecke2013-vv, Kim2015-mh}.

The Linnarsson group also modified their STRT-Seq protocol to be compatible with the C1 IFCs. In addition to reducing the reagent volume per cell, this reduced the labour of manually isolating cells \cite{Islam2014-dx}. After the addition of robotic automation for library preparation this eventually enabled the group to survey and catalogue neuronal subtypes in mouse cortex by investigating 3,005 cells from 67 individual mice \cite{Zeisel2015-mk}. The large number of cells from multiple mice allowed the authors to develop BackSPIN, a stable algorithm to cluster cells into neuronal cell types.

The group of Rickard Sandberg released the Smart-seq2 protocol, a refined version of Smart-seq which used less expensive off the shelf reagents \cite{Picelli2013-px, Picelli2014-hr}, and also used smaller volumes in individual wells. The microwell based Smart-seq2 protocol was more appropriate when cells could not be provided in a dense suspension, as is the case e.g. when studying early embryonic cells \cite{Deng2014-ud}.

Researchers also noted that some cell types were difficult to capture on the C1 IFC chips (for example, in the study by \citet{Zeisel2015-mk} the average successful cell capture rate was 41\%). With the lower reagent price per volume, the Smart-seq2 protocol gave an alternative with greater control, though at the cost of increased labour. The strategy of relying on off-the-shelf reagents and not needing the expensive IFC reduced the price per cell. The dominant cost factor for Smart-seq2 at this point was the reliance on the Nextera kit for barcoding. The cost per cell was further reduced by in-house production of the transposase Tn5, a variant of the active enzyme in Illumina’s Nextera XT tagmentation kit \cite{Picelli2014-ni}. The same Tn5 transposase was used by the Linnarsson lab to reduce the cost of the STRT-seq technology \cite{Islam2014-dx}.

\section{Surpassing thousands of cells}

With well-calibrated flow cytometers, cells can quickly be isolated in individual wells of 96 or 384 microwell plates. Once cells are available as a single cell suspension, researchers can use this strategy to populate large numbers of plates with their cells of interest, the bottleneck becoming the processing of the plates. With this in mind, Jaitin et al modified the CEL-seq protocol to be compatible with robotic automation in massively parallel single-cell RNA-sequencing (MARS-Seq, \citet{Jaitin2014-pk}). This allowed the Amit team to decrease the labour of processing plates filled with isolated cells and scale up massively, investigating 4,000 cells in one study \cite{Jaitin2014-pk}. Several laboratories have set up automation procedures for their standard protocol of choice \cite{Zeisel2015-mk, Soumillon2014-mf}. The refined CEL-seq2 method \cite{Hashimshony2016-ul} was automated in form of the SORT-seq method \cite{Muraro2016-zt}. The large number of samples allowed researchers to develop a probabilistic mixture model that allowed them to assign cells to immune cell types without known markers \cite{Jaitin2014-pk}.

In CEL-seq and derivative protocols \cite{Hashimshony2012-am, Jaitin2014-pk, Hashimshony2016-ul, Velten2015-ve}, it had been demonstrated that as long as you had isolated and barcoded the cDNA material, the following steps of amplification and library preparation could be done in a single unit. The bottleneck to improving throughput was pinpointed to two major factors: isolation of cells and the ability to generate enough multiplexing barcodes to investigate large numbers of cells in parallel. Methods had emerged to randomly capture and manipulate individual cells in nanoliter droplet emulsions \cite{Mazutis2013-rd}. The challenge of creating cDNA and barcode the material in the individual droplets was solved by \citet{Klein2015-ti} and \citet{Macosko2015-jb} by delivering beads coated with barcoded sequences into the droplets in the inDrop and Drop-seq methods, respectively.

The reverse droplets have miniscule volumes of about 1 nL per cell, further reducing the reagent cost per cell. However, to avoid capturing two cells in a single droplet, the random isolation must be rate limited. This means the efficiency of capturing any given cell by a unique bead is low (in the order of 5-10\% \cite{Klein2015-ti, Macosko2015-jb}) and therefore the barcode space must be sufficiently large to allow for a great number of unused sequences. This is a challenge considering the molecular properties of the barcodes need to be accounted for during the barcode design \cite{Costea2013-oj}.

A benefit of the droplet microfluidics is that it is simple to manufacture the components. The plans and details for the Drop-seq system was made public online at \url{http://mccarrolllab.com/dropseq/}. This spread the use of the technology, and has enabled researchers to customize it to their needs. Still, optimization and experience with microfluidics is needed for optimal results. The company 10x Genomics commercialised the material required (device and reagents) to perform the inDrop method, spreading the technology worldwide \cite{10x_Genomics_Inc2016-do}. In their implementation, up to 8 independent cell pools can be processed simultaneously, allowing the parallelisation of several experiments in a single run. The technology was demonstrated in a massive study of 250,000 cells \cite{Zheng2017-th}. Recently, Illumina and Bio-Rad also announced a nanodroplet based single cell isolation system \cite{Illumina_Inc2017-wj}.

An alternative strategy for massively parallel cell isolation is to deposit beads into picoliter wells, and randomly load them with cells at limiting dilution \cite{Christina_Fan2015-dy, Gierahn2017-xv, Bose2015-dt}. Beside decreasing the reaction volume, the picowell systems are easier to control, and more portable. This allows for more rapid collection of fresh cells in e.g. clinical settings, further improving the ability to make single cell observations.

A related strategy by \citet{Vickovic2016-or} consists of FACS sorting cells onto the surface of an array with attached barcoded Poly(dT) capture probes. The throughput is estimated to be 10,000 cells over two days. Since cells are not randomly isolated but actively placed, the capture efficiency per cell should be better depending on the flow sorter.

\section{On the horizon: hundreds of thousands to millions of cells}

Rate limiting the number of cells in random capture system to avoid capturing multiple cells at once prohibits further scaling of these methods. Two new methods have been developed to overcome these issues, making use of sequential in situ barcoding \cite{Rosenberg2017-jt, Cao2017-ux}.

In the in situ barcoding approaches, cells are permeabilized and fixed with formaldehyde \cite{Rosenberg2017-jt} or methanol \cite{Cao2017-ux}. The fixed cells are then divided into small fractions of reactions where in the first round cDNA is generated from RNA and all cells in a fraction are marked with a unique barcode. In subsequent steps, fractions are pooled together, and re-divided into fractions. In the new fractions a second barcode is appended to the cDNA. The low probability of cells going together into the sequential fractions means each cell will get a unique sequence of barcodes, while the cells have actually never been isolated. In the study of \textit{Cao et al}, this technique was applied to \textit{C. elegans} and the researchers were able to obtain sequencing data for about 50 copies of each known cell type in the worm, providing a single-cell atlas of a whole animal \cite{Cao2017-ux}. Cell types could be identified in an unbiased manner by first creating a low-dimensional representation through \textit{t-distributed stochastic neighbour embedding} (t-SNE, \citet{Van_der_Maaten2008-lh}), then applying the \name{Density Peak} clustering algorithm \cite{Rodriguez2014-mc}. The high copy number of the cell types allowed the low-dimensional representation to be well represented with distinct groups.

Currently, the major cost limitation is library preparation and cDNA sequencing. To identify cell types and regulatory networks, relatively shallow sequencing suffices \cite{Heimberg2016-qw, Pollen2014-cs}, but the sequencing cost is still prohibitive, even at shallow depths, when wishing to analyse hundreds of thousands of cells. Recent announcements promise slightly cheaper sequencing from higher throughput \cite{Illumina_Inc2017-zg}, albeit some radical change in sequencing technology might be needed to further drive down sequencing cost.

Beyond sequencing, the limitation is obtaining cells. In some cases, cells might not be easy to isolate and in many interesting cases, it is difficult to obtain a single cell suspension as cell viability is comprimised by the tissue disaggregation. In line with this, two laboratories in parallel adapted single-cell transcriptomics to isolated nuclei, allowing work with tissues where harsh dissociation protocols will damage RNA integrity \cite{Habib2016-jm, Habib2017-jk, Lake2016-zb}. Moreover, stored material can be used in nuclear single-cell RNA analysis, as it is compatible with cell fixation. Recent work has shown that cells can be preserved prior to preparation for single cell RNA-sequencing, increasing the ability to gather usable material without reducing the complexity of the transcriptome \cite{Guillaumet-Adkins2017-po, Alles2017-vi} and potentially use archived material.

A particularly telling example of the improvements in scaling which have happened over the years is from the Regev lab. This lab initially used 18 cells \cite{Shalek2014-gu} (microwell plates), scaled to 2,000 cells \cite{Shalek2014-gu} (microfluidics) and then to 200,000 cells \cite{Dixit2016-qx} (nanodroplets) of the same cell type over the last 4 years. The field of transcriptomics has long been cursed by the so called ``large P small N problem'', where the number of observations (cells, N) is much smaller than the number of variables (genes, P). With hundreds of thousands of cells, each expressing up to 10,000 genes, this is no longer the case, and in the coming years we will see a lot of interesting results from this.

Recently, single cell studies have started including artificial perturbations of the system, from which direct regulatory information can be gained using relatively simple linear models \cite{Dixit2016-qx, Jaitin2016-sj, Adamson2016-mt, Datlinger2017-aa}. It has been widely accepted that simple analysis methods with a lot of data perform better than complex methods with small amounts of data \cite{Halevy2009-uj}. A good recent illustration is the work of Esteva et al, where a gold standard data set of 1,000 images was increased to one with 100,000, images, allowing the researchers to train a neural network which performed better than trained dermatologists in clinical classification of skin lesions \cite{Esteva2017-cw}. When studies reach millions of cells, even rare cell types will be identifiable without issue, and we will have an unbiased view of transcriptional diversity.

\section{Retaining spatial context}

\begin{figure}
    \centering
    \centerline{\includegraphics[width=.75\textwidth]{"SpatialTechnologies"}}
    \caption[Expression in spatial context]{\textbf{Expression in spatial context.} Many recent studies not only quantify gene expression in single cells, but also retain information about the spatial origin of the cells. Size of symbols correspond to area of tissue investigated, ranging from 20  \(\mu\)m \(\times\) 20  \(\mu\)m (TIVA) to 6.2 mm \(\times\) 6.6 mm (ST). Squares indicate methods that measure proteins, while circles indicate RNA measurement. Spatial Transcriptomics is a special case, as it measures expression in circular regions of 50 \(\mu\)m radius rather than single cells.}
    \label{fig:spatial}
\end{figure}

The increasingly large sample sizes of single cells is one aspect of technological improvement. In addition to this, many new experimental technologoes allow the spatial information of cells in tissues to be preserved. This will allow researchers to investigate how cell communication affects transcriptional regulation. Technologies are still emerging (Figure \ref{fig:spatial}) and are starting to achieve enough scale to be useful. This will be a very promising field in the future.

\section{Biological insights gained and structure of this thesis}

Studies of single-cell transcriptomes allow us to directly investigate properties of individual cells, i.e. mRNA abundance. Thus gene regulation is analyzed at the single cell level and, unlike traditional traditional RNA-sequencing, cell-to-cell heterogeneity can be considered.

There can be multiple possible sources of cellular heterogeneity in a population. 1) Expression can be intrinsically heterogenouos. 2) A population can consist of multiple distinct cell types, expressing different genes. 3) An underlying process modulates expression of many genes, in a continuous fashion.

The latter point is the focus of this thesis. By measuring gene expression in development, differentiation, or other responses, we can start to understand cellular phenotypes as well as the regulatory processes that determine these phenotypes. In many experiments cells are sampled at many time points and gene expression is assessed. To analyse general gene expression patterns, we need to use a non-parametric analysis framework. In Chapter \ref{ch:zebrafish} we discuss this.

Actively collecting cells requires large experimental resources, and ignores heterogeneity in development or response to stimuli. Since transcriptome data is extremely rich, the continuous differences between measured cells can be identified from the data alone. The task of identifying the process or trajectory has been codified in the field as \textit{Pseudotime}. In Chapter \ref{ch:zebrafish} we describe how non-parametric models can also be used for this task, and applied to study blood development.

In Chapter \ref{ch:malaria}, we consider the problem of studying expression changes over time when cells are sampled from multiple unlabeled cell populations which act differently over time. We present a method to identify and deconvolve multiple simulatneuous expression patterns using the same model framework as in Chapter \ref{ch:zebrafish}.

Finally, in Chapter \ref{ch:spatial} we consider genes which depend on spatial coordinates, rather than a time value. We then conclude the thesis by disscusing our conclusions and give an outlook towards future work.

We start however, in Chapter \ref{ch:power} by assessing the technical performance of various methods mentioned in this chapter. If we wish to gain biological insights from these data, we need to know how quantitative and sensitive the different techniques are. This also guides us in our choices of experimental design in the following chapters.
